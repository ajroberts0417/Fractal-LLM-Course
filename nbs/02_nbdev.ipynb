{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Publishing blog posts directly from Notebooks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Goals:  \n",
    "- Publish your first blog post.  \n",
    "- Create a full, proper python library for the custom Sentiment Analysis pipeline from last time.   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we take a closer look at the `nbdev` library. `nbdev` is a powerful tool based on two key ideas:  \n",
    "- Literate programming. \n",
    "- Exploratory programming.  \n",
    "\n",
    "\n",
    "In Literate Programming, descriptions (documentation) are woven directly into a project's source code.  \n",
    "This is opposite of how most codebases are set up, where documentation exists as a separate set of files.  \n",
    "\n",
    "How is this different from parsing source code and comments into documentation? In Literate Programming the code, tests, and documentation are all first-class citizens. And with `nbdev`, the Notebook is the single source of truth for all of these. Think about what this truly means, and just how much overhead work it removes.   \n",
    "\n",
    "Instead of having to independently manage code, docs, and tests, everything can be done in Notebooks. If the notebook runs, you know your code will run. And you can directly document and test your code in the notebook as you develop.    \n",
    "\n",
    "Exploratory programming is, as the name suggests, an open-ended approach to coding when exploring unknown domains or areas. Folks often use it at the start of a project, when the requirements or scope are not yet flushed out.  \n",
    "\n",
    "Try things out, figure out how they work, what they do. Poke around. Explore. Follow that curiosity. Have fun! Can always restart the Notebook, no fear around trying things - very little to no downside.  \n",
    "\n",
    "`nbdev` combines these two ideas. We can then mix and match them in different doses as needed.  \n",
    "\n",
    "This notebook will turn our previous, first runs into a proper python library.  \n",
    "It will have documentation and tests directly in the notebook.  \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| default_exp lesson_2.mock_pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export  \n",
    "from transformers import AutoConfig\n",
    "from transformers import AutoTokenizer\n",
    "from transformers import AutoModelForSequenceClassification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#| export  \n",
    "\n",
    "class SentimentPipeline:\n",
    "    def __init__(self, model_name):\n",
    "        \"\"\"\n",
    "        Sentiment Analysis pipeline.\n",
    "        \"\"\"\n",
    "        self.model_name = model_name\n",
    "        self.config = AutoConfig.from_pretrained(self.model_name)\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n",
    "        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)\n",
    "\n",
    "\n",
    "    def preprocess(self, text: str):\n",
    "        \"\"\"\n",
    "        Sends `text` through the LLM's tokenizer.  \n",
    "        The tokenizers turns words and characters into special inputs for the LLM.\n",
    "        \"\"\"\n",
    "        tokenized_inputs = self.tokenizer(text, return_tensors='pt')\n",
    "        return tokenized_inputs\n",
    "    \n",
    "\n",
    "    def forward(self, text: str):\n",
    "        \"\"\"\n",
    "        First we preprocess the `text` into tokens.\n",
    "        Then we send the `token_inputs` to the model.\n",
    "        \"\"\"\n",
    "        token_inputs = self.preprocess(text)\n",
    "        outputs = self.model(**token_inputs)\n",
    "        return outputs\n",
    "    \n",
    "\n",
    "    def process_outputs(self, outs):\n",
    "        \"\"\"\n",
    "        Here is where HuggingFace does the most for us via `pipeline`.  \n",
    "        \"\"\"\n",
    "        # grab the raw \"scores\" that from the model for Positive and Negative labels\n",
    "        logits = outs.logits\n",
    "\n",
    "        # find the strongest label score, aka the model's decision\n",
    "        pred_idx = logits.argmax(1).item()\n",
    "\n",
    "        # use the `config` object to find the class label\n",
    "        pred_label = self.config.id2label[pred_idx]  \n",
    "\n",
    "        # calculate the human-readable number for the score\n",
    "        pred_score = logits.softmax(-1)[:, pred_idx].item()\n",
    "\n",
    "        return {\n",
    "            'label': pred_label,\n",
    "            'score': pred_score, \n",
    "        }\n",
    "    \n",
    "    def __call__(self, text: str):\n",
    "        model_outs = self.forward(text)\n",
    "        preds = self.process_outputs(model_outs)\n",
    "        return preds\n",
    "    \n",
    "    def __repr__(self):\n",
    "        return f\"SentimentAnalysis_{self.model_name}\"\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "python3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
