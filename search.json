[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Fractal LLMs Course",
    "section": "",
    "text": "Fractal-U course on LLMs."
  },
  {
    "objectID": "index.html#installation",
    "href": "index.html#installation",
    "title": "Fractal LLMs Course",
    "section": "Installation",
    "text": "Installation\npip install Fractal_LLM_Course"
  },
  {
    "objectID": "index.html#usage",
    "href": "index.html#usage",
    "title": "Fractal LLMs Course",
    "section": "Usage",
    "text": "Usage\nThere is a folder for each lesson inside Fractal_LLM_Course/."
  },
  {
    "objectID": "blog/index.html",
    "href": "blog/index.html",
    "title": "Fractal-U LLM Blog",
    "section": "",
    "text": "No matching items"
  },
  {
    "objectID": "01_first_runs.html",
    "href": "01_first_runs.html",
    "title": "Run a Large Language Model using the HuggingFace Transformers API.",
    "section": "",
    "text": "The cells below are good defaults for development.\nThe autoreload lines help load libraries on the fly, while they are changing. This works well with the editable install we created via pip install -e .\nThis means we can edit the source code directly and have the change reflected live in the notebook.\n%load_ext autoreload\n%autoreload 2\n%matplotlib inline\n\nThe autoreload extension is already loaded. To reload it, use:\n  %reload_ext autoreload"
  },
  {
    "objectID": "01_first_runs.html#first-a-pipeline",
    "href": "01_first_runs.html#first-a-pipeline",
    "title": "Run a Large Language Model using the HuggingFace Transformers API.",
    "section": "First, a Pipeline",
    "text": "First, a Pipeline\nA HuggingFace model is based on 3 key pieces: 1. Config file.\n2. Preprocessor file.\n3. Model file.\nThe HuggingFace API gives us a way of automatically using these pieces directly: the pipeline.\nLet‚Äôs get right it and create a Sentiment Analysis pipeline.\n\n# load in the pipeline object from huggingface\nfrom transformers import pipeline\n\n# create the sentiment analysis pipeline\nclassifier = pipeline(\"sentiment-analysis\")\n\n/Users/cck/mambaforge/envs/llm_base/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\nNo model was supplied, defaulted to distilbert-base-uncased-finetuned-sst-2-english and revision af0f99b (https://huggingface.co/distilbert-base-uncased-finetuned-sst-2-english).\nUsing a pipeline without specifying a model name and revision in production is not recommended.\nDownloading (‚Ä¶)lve/main/config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 629/629 [00:00&lt;00:00, 1.06MB/s]\nDownloading model.safetensors: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 268M/268M [00:34&lt;00:00, 7.76MB/s] \nDownloading (‚Ä¶)okenizer_config.json: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 48.0/48.0 [00:00&lt;00:00, 432kB/s]\nDownloading (‚Ä¶)solve/main/vocab.txt: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 232k/232k [00:00&lt;00:00, 9.00MB/s]\n\n\nWe can see in the output message above that HuggingFace automatically picked a decent, default model for us since we didn‚Äôt specify one. Specifically, it chose a distilbert model.\nWe will learn more about what exactly distilbert is and how it works later on. For now, think of it as a useful NLP genie who can tell us how it feels about a given sentence.\n\n# example from the HuggingFace tutorial\nclassifier(\"We are very happy to show you the ü§ó Transformers library.\")\n\n[{'label': 'POSITIVE', 'score': 0.9997795224189758}]\n\n\n\n# passing in several sentences at once, inside a python list\nresults = classifier([\n    \"We are very happy to show you the ü§ó Transformers library.\",\n    \"We hope you don't hate it.\",\n    \"I love Fractal! I'm so glad it's not a cult!\", \n])\n\n# print the output of each results\nfor result in results:\n    print(f\"label: {result['label']}, with score: {round(result['score'], 4)}\")\n\nlabel: POSITIVE, with score: 0.9998\nlabel: NEGATIVE, with score: 0.5309\nlabel: POSITIVE, with score: 0.999"
  },
  {
    "objectID": "01_first_runs.html#more-hugging-face-magic",
    "href": "01_first_runs.html#more-hugging-face-magic",
    "title": "Run a Large Language Model using the HuggingFace Transformers API.",
    "section": "More Hugging Face Magic",
    "text": "More Hugging Face Magic\nAuto classes.\n\nfrom transformers import AutoConfig\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForSequenceClassification\nfrom transformers import AutoModel\n\n\nmodel_name = \"nghuyong/ernie-3.0-nano-zh\"\ntweet_classifier_model = \"vinai/bertweet-base\"\n\n\nbertweet = AutoModel.from_pretrained(tweet_classifier_model)\n\n# For transformers v4.x+:\ntokenizer = AutoTokenizer.from_pretrained(tweet_classifier_model, use_fast=False)# It seems like the torch library is not imported. Let's import it.\n\nemoji is not installed, thus not converting emoticons or emojis into text. Install emoji: pip3 install emoji==0.6.0\nSpecial tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n\n\n\nimport torch\n\n\n# INPUT TWEET IS ALREADY NORMALIZED!\nline = \"SC has first two presumptive cases of coronavirus , DHEC confirms HTTPURL via @USER :cry:\"\n\ninput_ids = torch.tensor([tokenizer.encode(line)])\n\nwith torch.no_grad():\n    features = bertweet(input_ids)  # Models outputs are now tuples\n\n\nfeatures\n\nBaseModelOutputWithPoolingAndCrossAttentions(last_hidden_state=tensor([[[-0.0261,  0.2147,  0.1159,  ...,  0.0314,  0.0336, -0.1419],\n         [ 0.0986, -0.0205,  0.2265,  ...,  0.0828, -0.2993,  0.4767],\n         [-0.1011,  0.2133, -0.2283,  ...,  0.0797, -0.1762, -0.2632],\n         ...,\n         [-0.3448, -0.2996, -0.2430,  ..., -0.3354,  0.2429,  0.3029],\n         [-0.5279, -0.2429,  0.0758,  ..., -0.1733,  0.0389,  0.0513],\n         [-0.0425,  0.2355,  0.1219,  ...,  0.0018,  0.0732, -0.1305]]]), pooler_output=tensor([[ 2.1684e-01, -1.6747e-01, -3.9913e-02, -1.6048e-01,  1.2537e-01,\n         -7.5435e-02,  2.1886e-01, -1.3510e-01,  2.0169e-01, -2.1097e-01,\n         -9.4783e-02, -5.3385e-02, -2.2015e-01,  1.3985e-02,  1.5082e-01,\n         -6.2458e-02, -1.4717e-01, -6.7478e-02,  2.4149e-02,  1.7152e-01,\n         -1.1483e-01, -1.7264e-01,  2.9670e-01, -1.6612e-02, -2.3634e-02,\n          3.5211e-02, -1.6087e-01, -3.7129e-02,  4.9395e-02, -5.8116e-02,\n         -5.6990e-02, -1.5559e-01,  1.6120e-01,  5.6176e-02,  1.7266e-01,\n         -5.9471e-02,  2.1309e-01,  1.2466e-01, -1.2592e-01,  9.7800e-02,\n         -1.5980e-01, -4.7554e-02,  1.1069e-01,  2.2540e-02, -7.0860e-02,\n          3.4330e-02, -1.3061e-01,  3.6223e-02,  3.8687e-01, -4.9398e-02,\n         -6.2529e-03,  1.1077e-01, -6.5433e-02, -1.0200e-02, -5.4492e-03,\n          1.2476e-01, -5.6954e-03,  6.2194e-02, -2.2040e-01,  2.3035e-01,\n          4.0335e-02,  4.2737e-01, -2.5728e-01, -4.2542e-01, -1.2840e-02,\n         -1.3663e-01, -4.3941e-03,  1.1903e-01,  4.6278e-01,  2.3251e-01,\n          2.7170e-01,  1.0339e-01, -2.4488e-01, -1.2348e-02, -9.7118e-02,\n         -1.6682e-01,  6.5080e-02, -2.9772e-02,  1.3511e-01,  2.4833e-02,\n         -2.9946e-02, -3.5176e-01,  2.3219e-01, -9.5713e-02, -2.5918e-01,\n          2.1088e-01,  1.0469e-01,  6.2564e-02, -6.9195e-02,  2.1744e-01,\n         -1.8241e-01, -7.7701e-02, -1.3959e-01, -2.1408e-01, -1.0395e-01,\n         -2.8095e-02,  2.9942e-04,  2.3257e-01, -1.2731e-01, -1.7985e-01,\n         -1.8892e-01,  8.1731e-02, -3.7738e-03,  6.8216e-03,  4.1659e-03,\n         -8.9084e-02, -3.5341e-02,  2.2507e-01,  2.8873e-02, -7.7968e-02,\n         -2.0763e-02, -1.6699e-01, -2.2962e-01, -1.6147e-01,  1.9951e-01,\n         -2.0290e-02, -3.0334e-01,  2.8734e-01,  2.3261e-01,  7.0353e-02,\n         -3.4001e-02,  2.0040e-01,  1.5577e-02,  3.0432e-01,  5.7032e-02,\n         -3.4262e-02,  6.6559e-02, -6.2958e-02,  1.2308e-01, -2.3498e-01,\n          5.8435e-02, -1.7375e-02,  1.5279e-01, -1.6965e-01,  1.1444e-01,\n         -1.9653e-02,  1.4225e-01,  8.3226e-02,  1.7470e-01,  1.6492e-01,\n          2.9033e-03, -2.9698e-01, -1.7966e-02,  3.3161e-01,  2.6770e-03,\n          3.0237e-01, -1.2641e-01,  1.4140e-01, -9.1238e-02, -4.3958e-02,\n         -2.0406e-03, -1.0386e-01, -1.9405e-01,  1.6783e-01, -4.5707e-02,\n         -8.6509e-02,  4.4101e-04,  6.7585e-02,  5.1672e-02, -9.1920e-02,\n          2.1051e-01, -2.8929e-01,  1.1323e-02, -1.5257e-01,  7.3889e-02,\n         -7.6998e-02, -1.5864e-01, -5.7710e-02, -1.4706e-01, -2.0447e-02,\n         -1.4777e-01, -1.7777e-01, -6.2066e-01, -2.8002e-01,  2.0328e-01,\n          1.6720e-01, -1.3829e-01,  9.3785e-02,  1.9930e-01,  6.8548e-02,\n         -8.3035e-03,  1.0518e-01, -2.2478e-01,  3.6735e-02, -1.4841e-01,\n          2.2288e-01, -9.9642e-02, -9.6726e-02,  6.0620e-02,  3.3674e-02,\n          7.1847e-02, -1.7697e-02,  2.5305e-01,  1.8194e-01, -3.8007e-01,\n         -1.7328e-01,  1.5387e-01, -1.9752e-01,  5.8195e-02,  1.4141e-01,\n          1.7599e-01,  9.9589e-02, -1.7539e-01,  3.9723e-02,  5.7362e-02,\n         -6.0153e-03, -7.4778e-02, -3.9814e-02,  4.2532e-03, -6.1438e-03,\n         -2.7549e-01, -1.7463e-01, -1.0434e-01, -2.8234e-01, -1.1606e-01,\n          2.2520e-01, -2.6030e-01, -5.6626e-02, -4.5074e-01,  2.0554e-01,\n          2.4415e-01, -2.4389e-01,  1.4430e-01,  2.7835e-02, -8.4409e-02,\n         -5.5983e-04,  4.9588e-01,  7.3265e-02, -1.3965e-01, -3.0254e-01,\n         -3.4468e-02, -8.2590e-02,  1.2788e-01, -1.6157e-02,  1.7172e-01,\n          6.1288e-01,  1.5453e-01,  9.4416e-02, -1.1867e-01, -2.8974e-02,\n         -2.2069e-01, -1.8120e-01,  9.5515e-02, -1.8660e-01,  3.1271e-02,\n          3.6478e-02,  4.3989e-01,  5.9990e-02, -2.1676e-01,  9.2674e-02,\n         -1.1439e-01, -2.4943e-01, -2.9657e-01,  1.3715e-01, -5.5204e-02,\n          8.1869e-02, -2.5680e-03,  4.9731e-03,  2.9959e-01,  1.8850e-01,\n          9.5238e-02,  1.7245e-01, -2.8302e-01, -1.0291e-01, -1.3128e-01,\n         -7.4131e-02,  6.4492e-02, -2.6746e-01, -7.7197e-02, -1.6304e-01,\n         -2.2387e-01, -1.2678e-01,  6.6664e-02, -2.5839e-02, -8.8316e-02,\n         -2.3827e-01, -6.9970e-03,  1.8078e-01, -6.2181e-02, -3.8105e-01,\n          1.2478e-02,  2.3644e-01, -2.2813e-01, -6.5327e-02, -4.2093e-02,\n         -4.9957e-02, -1.6963e-02,  2.8927e-01,  1.2748e-01, -1.6388e-02,\n         -1.4192e-01, -1.0516e-01, -7.7114e-03,  3.0210e-01,  7.8765e-02,\n         -2.9639e-01,  1.6735e-01,  1.0467e-02,  2.1078e-01,  7.6494e-02,\n         -1.1333e-01, -1.7217e-01,  1.1373e-01, -2.2313e-01, -1.2148e-01,\n         -1.9967e-01, -1.0848e-01, -1.8277e-03,  1.9473e-01,  1.9243e-01,\n          1.7690e-01, -2.0756e-02,  2.1948e-01,  2.6942e-01, -6.2986e-03,\n          1.4327e-01,  1.1615e-01,  2.0209e-01,  3.8537e-02, -4.6930e-02,\n         -7.8353e-02, -1.7991e-01, -1.6937e-01, -4.8626e-02,  2.6269e-02,\n          1.7385e-02, -1.7453e-01,  2.6845e-02, -5.6886e-02,  2.7073e-01,\n          2.8761e-01, -1.0229e-01,  1.4652e-01, -8.4829e-02, -1.5249e-01,\n         -1.6665e-01,  1.6805e-01,  7.7209e-02,  5.8676e-02,  4.0058e-02,\n         -1.5571e-01, -1.2718e-01,  3.1281e-01, -9.1534e-03,  1.3576e-01,\n          3.9473e-01,  2.4109e-02, -3.8084e-02, -1.4643e-01,  2.8824e-02,\n         -3.2364e-02, -1.4315e-01,  3.7451e-02, -4.4504e-02,  1.5163e-01,\n         -2.8780e-01,  1.6395e-01,  1.3348e-01, -2.2630e-01,  7.0919e-02,\n         -2.1954e-01,  2.5653e-02, -8.2631e-02, -1.2159e-01, -1.5556e-01,\n          7.7520e-02, -1.2948e-01, -2.3807e-01,  2.7228e-01, -4.2869e-02,\n         -7.8903e-03,  8.9008e-02,  3.2700e-01, -1.7110e-01, -1.3331e-01,\n          2.4333e-02,  2.5774e-02, -3.7812e-01, -1.7119e-01, -7.4228e-02,\n          1.4139e-01, -1.0524e-01, -2.4698e-01,  1.0323e-01, -1.0664e-01,\n          9.5311e-02, -3.6480e-01,  1.9375e-01,  2.4034e-01, -1.3027e-01,\n          2.6347e-01, -2.1574e-02,  7.0733e-03, -4.5205e-01,  1.0983e-01,\n          7.4580e-02,  1.9370e-01,  5.6969e-02,  3.0360e-01, -1.0367e-01,\n         -6.9653e-02, -2.0863e-01,  1.1197e-01, -8.3405e-02, -4.3823e-02,\n         -1.0581e-01, -2.6405e-03,  1.2920e-01,  7.2932e-02, -8.2181e-03,\n         -1.5625e-01,  2.5517e-01, -3.2143e-01, -1.0550e-01, -8.6524e-02,\n          1.3654e-01,  2.1519e-01,  3.3233e-02,  1.1481e-01, -2.7192e-01,\n          1.5108e-01, -1.2987e-01,  5.7868e-02,  4.9990e-02, -5.4458e-02,\n          2.7341e-02, -1.0211e-01, -7.1317e-02, -1.0423e-01, -4.7862e-02,\n         -1.6483e-02, -1.6297e-01, -1.1742e-01, -1.3970e-02, -9.0472e-02,\n          3.6632e-02,  5.2472e-02,  1.0371e-01,  5.5842e-02, -1.8505e-01,\n         -1.7271e-01, -3.4367e-01,  2.3774e-01, -2.4568e-01, -6.8554e-02,\n         -1.1043e-01, -2.1823e-01, -3.3877e-01, -1.8825e-01, -1.3074e-01,\n          2.0080e-01, -4.3499e-02, -1.1833e-03, -1.0494e-02,  9.8839e-02,\n         -9.8610e-02,  1.0916e-01, -1.2520e-01,  2.2091e-01,  1.8034e-01,\n          1.3691e-01,  5.8596e-02,  9.1620e-02,  2.5686e-01, -1.6616e-01,\n         -2.1491e-01,  1.5801e-01, -6.9085e-02, -1.1327e-01,  2.2038e-01,\n          4.0991e-02, -1.2667e-01, -2.1626e-01,  9.1708e-02, -2.1187e-01,\n          3.8479e-02,  1.3006e-02,  2.8096e-01,  5.8074e-02,  6.4363e-02,\n         -1.9326e-01,  5.0338e-02, -1.6850e-01,  2.5039e-01, -1.2964e-01,\n         -4.5641e-02, -1.9423e-01, -2.0506e-01,  2.7561e-01, -2.1644e-01,\n          1.3510e-01, -1.5607e-01, -1.9618e-01,  3.6909e-01,  1.6661e-02,\n         -2.7980e-01,  1.6374e-01,  9.8737e-02, -4.2289e-02, -5.9343e-03,\n         -2.3921e-01, -9.5844e-02,  7.9161e-02,  4.8087e-02, -1.5758e-01,\n         -3.2436e-01, -2.1874e-01,  9.2943e-02, -1.7660e-01,  3.2471e-01,\n          4.1639e-02, -8.4214e-02, -1.1156e-01,  1.7573e-01, -1.4107e-01,\n          9.6379e-02, -8.0719e-02, -2.1352e-01,  1.9738e-01, -7.8069e-04,\n         -1.4115e-01, -1.4976e-01, -1.0283e-01,  2.7926e-01,  2.2314e-01,\n          2.6503e-01, -2.9287e-01,  5.3031e-03, -1.6676e-01, -1.7062e-01,\n          1.6481e-01, -6.6617e-02,  1.3794e-01,  1.2838e-01,  1.7721e-01,\n         -3.6212e-01,  1.9786e-03, -4.0427e-02, -1.4486e-01, -9.7480e-02,\n         -1.8925e-01,  4.2498e-01, -5.7728e-02, -4.3533e-02,  1.7206e-02,\n          1.3141e-01, -2.7031e-02, -1.0911e-01,  3.1601e-01,  5.3195e-02,\n          2.1432e-01, -1.2668e-01,  8.3884e-02, -3.1696e-01, -1.4914e-01,\n         -3.0770e-01,  5.2150e-01, -1.0679e-01,  1.0872e-01, -3.0105e-02,\n         -1.8292e-01,  2.4955e-01,  4.8210e-02,  6.5361e-02, -8.1284e-02,\n         -7.3967e-02,  2.1774e-01, -2.5905e-01, -9.9748e-02,  2.2861e-01,\n          2.0665e-01, -6.5433e-02, -1.4660e-01, -2.7731e-02, -3.7495e-01,\n         -3.3564e-01,  2.2604e-01,  1.2786e-01, -1.1509e-01, -3.2010e-01,\n          5.0551e-02, -5.2174e-02, -6.8957e-02, -3.2839e-01, -1.4177e-01,\n          1.2305e-01,  5.3620e-02, -2.2995e-01, -1.0491e-01, -7.8523e-02,\n         -5.8274e-02, -3.0538e-01,  2.1489e-01,  1.6900e-01,  1.0598e-01,\n          1.4898e-03, -8.4836e-02, -2.2781e-01,  6.4068e-02,  6.7883e-02,\n          5.4033e-01,  7.4442e-02,  2.1099e-01, -2.4285e-01, -9.5264e-02,\n         -7.1959e-02,  7.2113e-02,  1.9963e-01,  7.2252e-02, -1.8008e-01,\n          1.1053e-02,  7.1147e-03,  1.3077e-01, -1.1621e-01,  1.3477e-01,\n          1.8277e-01, -1.2061e-01,  2.5727e-01, -4.8499e-02, -7.5046e-02,\n         -1.1551e-01,  5.9584e-02,  1.1659e-01, -2.9556e-01,  3.4345e-02,\n          2.3334e-01, -3.8725e-02, -4.8951e-02,  1.2001e-01, -1.2271e-01,\n          1.2176e-01,  1.7248e-01,  1.7510e-01, -1.0586e-01,  1.4408e-01,\n          4.6973e-02, -1.9982e-01, -3.1675e-01,  1.8192e-01, -4.9504e-02,\n         -1.1049e-01,  5.1719e-02, -3.8881e-01, -3.7701e-01, -2.3664e-01,\n          6.1054e-02, -1.6371e-01, -1.8980e-02, -1.0350e-02, -1.8236e-02,\n         -3.1771e-01,  1.7057e-02, -6.7176e-02,  3.0066e-02,  1.2955e-01,\n          2.5587e-02, -1.3062e-02,  1.5314e-01,  1.2715e-01,  2.5056e-01,\n         -2.6158e-01, -7.3815e-02, -2.8139e-01, -6.8489e-02, -2.4890e-01,\n         -1.0459e-01,  2.1866e-01, -1.3652e-02,  2.2082e-01,  1.4452e-01,\n          1.2156e-01, -4.2408e-03,  2.5653e-01, -1.4201e-02, -1.3602e-01,\n          2.4607e-02, -2.4028e-01,  9.0389e-02, -2.0443e-01, -2.6975e-01,\n          2.9034e-01, -8.2160e-02, -4.7939e-02,  2.1328e-01,  4.1331e-02,\n         -1.3397e-01, -5.8570e-02, -1.4730e-01,  2.0228e-01,  2.1142e-01,\n          1.9471e-01, -9.2305e-02,  2.7115e-02,  2.2871e-02, -2.3399e-01,\n         -6.6573e-02, -3.1556e-02, -6.7305e-02, -9.1438e-02, -2.6135e-01,\n         -7.6051e-02, -1.3300e-01,  2.3206e-01,  2.1293e-01, -4.6348e-02,\n         -1.7028e-01, -3.1770e-02,  3.3346e-03, -7.7843e-03,  2.5576e-01,\n          4.3425e-02,  1.1490e-02, -9.8304e-02, -2.2572e-01, -5.6736e-02,\n          2.4170e-01, -8.3043e-02, -3.2750e-01, -1.8894e-01, -7.3210e-02,\n          2.4887e-02, -5.6985e-02,  3.2579e-01, -7.0417e-02,  5.7850e-02,\n         -5.1130e-02, -6.9433e-02, -1.9004e-01,  1.9591e-02, -1.7293e-01,\n         -1.5911e-01,  9.1796e-02,  3.4482e-01, -8.8054e-03,  9.0982e-02,\n         -2.2528e-02, -1.4741e-01,  5.4736e-02, -2.4447e-01, -1.3338e-01,\n         -1.2902e-01, -1.2377e-01, -2.4834e-01, -2.0397e-02, -4.5321e-03,\n          1.2454e-01, -4.7694e-02,  1.7699e-01, -3.2227e-01,  2.7142e-01,\n         -1.2625e-01, -2.3601e-01,  9.6091e-02,  3.3450e-01, -1.4860e-01,\n         -1.3938e-01,  1.1786e-01,  2.0373e-02, -1.1923e-01, -2.8852e-01,\n         -2.2158e-01,  1.6883e-01,  1.2095e-01,  3.1874e-01, -3.6485e-01,\n          1.2620e-02, -6.6986e-02, -1.9560e-01]]), hidden_states=None, past_key_values=None, attentions=None, cross_attentions=None)"
  },
  {
    "objectID": "02_nbdev.html",
    "href": "02_nbdev.html",
    "title": "nbdev for Blogging and Building Python Libraries",
    "section": "",
    "text": "Create a blog and publish our first post.\n\nBuild a custom, dynamic python library for the Sentiment Analysis pipeline in 01_first_runs.ipynb."
  },
  {
    "objectID": "02_nbdev.html#goals",
    "href": "02_nbdev.html#goals",
    "title": "nbdev for Blogging and Building Python Libraries",
    "section": "",
    "text": "Create a blog and publish our first post.\n\nBuild a custom, dynamic python library for the Sentiment Analysis pipeline in 01_first_runs.ipynb."
  },
  {
    "objectID": "02_nbdev.html#intro",
    "href": "02_nbdev.html#intro",
    "title": "nbdev for Blogging and Building Python Libraries",
    "section": "Intro:",
    "text": "Intro:\nThis Notebook takes a closer look at the nbdev library. nbdev is a powerful tool built around two key ideas:\n- Literate Programming. - Exploratory Programming.\nThe next sections give an overview of these topics, and why their combination is useful for us.\n\nLiterate Programming\nIn Literate Programming, descriptions (documentation) are woven directly into a project‚Äôs source code. This is opposite from most codebases where documentation lives in a separate set of files. It also goes beyond tools like sphinx that instead parse comments and docstrings into documentation.\nCode, tests, and documentation are all first-class citizens in Literate Programming. In nbdev a Notebook is the single, unified source for all three things. Instead of having to independently manage code, docs, and tests, everything happens in the Notebook. If the Notebook runs then you know your code will run. The tight integration between what you‚Äôre doing (code), describing what you‚Äôre doing (documentation), and making sure it‚Äôs correct (tests) is a great approach for both research and thinking in general.\n\n\nExploratory Programming\nExploratory Programming is an open-ended approach for new problems and unknown domains. It‚Äôs very helpful at the start of a project before its scope or requirements are fully flushed out.\nThe interactive and dynamic nature of Notebooks is ideal for Exploratory Programming. It makes the barrier to try new things extremely low. And it‚Äôs fun! Jupyter also has many extra tools to inspect code and debug its outputs.\n\n\nCombining Literate and Exploratory Programming\nnbdev‚Äôs main workflow combines these two ideas. It‚Äôs a great combo for trying things out, figuring out what they do, and how they work. We can poke around and explore codebases in a much more interactive way than usual. Iterations are fast and cheap so it‚Äôs easy to follow any hit of curiosity. And if anything breaks, we can always restart the Notebook and try again!\nWe can also mix and match these ideas as needed. For example at the start of a project, while finding our footing, we might lean Exploratory. Then as the idea matures, we could lean Literate to refine and crystallize our approach.\nNow for our first goal: creating and publishing a blog post."
  },
  {
    "objectID": "02_nbdev.html#turning-notebooks-into-blog-posts",
    "href": "02_nbdev.html#turning-notebooks-into-blog-posts",
    "title": "nbdev for Blogging and Building Python Libraries",
    "section": "Turning Notebooks into Blog Posts",
    "text": "Turning Notebooks into Blog Posts\nFirst, a high-level summary of the steps to create the blog.\n\nHigh-Level Steps:\n\nCreate a new nbdev project.\n\nSet up the minimum requirements for an nbdev blog.\n\nPublish the blog to Github pages.\n\n\nNOTE: This section is based on these two references: - Official nbdev tutorial. - Blogging with nbdev.\n\nnbdev leverages an amazing tool called Quarto for blogging. Quarto is a publishing framework tailored to scientific and technical articles and posts. In a way it‚Äôs a blogging platform for Literate Programming, where a series of code cells tell a story and take the reader on a journey.\n\n\n\nCreating a new nbdev project\nnbdev works on top of a Git repo, so the step is creating an empty git repository. Here is a handy Github link that takes you straight to the page for creating new repos.\n\nNote: We need a completely empty repo, so don‚Äôt include a .gitignore or README.md.\n\nIn this example the empty repo is called sample_blog, but feel free to call it anything you‚Äôd like. We‚Äôre not married to this name either, we can always create new repos with different, better names.\nNext, clone this repo to your computer. Make sure to change the github link below to point to your repo instead.\n# clone the repo to your computer\ngit clone https://github.com/enzokro/sample_blog.git # &lt;-- ! link with your repo here\nNow we can move into this empty repo and let nbdev work its initialization magic. Run the nbdev_new command to get started. It will prompt you for some general info like as a short description about your project.\n# move into the new repo and initialize the nbdev project\ncd sample_blog/\nnbdev_new\nAll of the options and configs for your project are found in the settings.ini file. nbdev looks in this file for any info it needs for its commands.\nWhen nbdev_new finishes running, you will have a new nbdev project! Try running a git status command to see everything that was added.\nWe can now commit and push these changes to Github.\n# add, commit, and push the files created by nbdev\ngit add .\ngit commit -m'Initial nbdev project creation'\ngit push\nAs we mentioned earlier, nbdev leverages Quarto for publishing Notebooks. The next steps are turning this nbdev project into a proper Quarto blog.\n\n\nAdding Quarto to the Mix\nStart by activating the virtual environment:\n# acivate the environment\nmamba activate llm_base\nnbdev includes a way to install Quarto using the nbdev_install_quarto command. Go ahead and run it, but note that it will ask you for administrator privileges.\n# install quarto\nnbdev_install_quarto\nYou may need to refresh the terminal session before it can find the quarto commands. To be safe, open up a new terminal and re-activate the environment. Then the command below will check if Quarto was installed successfully.\n# shows us where quarto is installed\nwhich quarto \nNote that the nbs/ folder usually holds the Notebooks that become a project‚Äôs documentation, tests, and source code. To make sure Quarto can publish an nbdev blog we have to add some files and change this directory structure a bit.\nFirst let‚Äôs take a look at what the new blog-ready nbs/ folder will look like.\nMinimal Quarto blog folder structure:\nsample_blog\n‚îî‚îÄ‚îÄ‚îÄnbs/\n‚îÇ   ‚îÇ   _quarto.yml\n‚îÇ   ‚îÇ   index.ipynb\n‚îÇ   ‚îî‚îÄ‚îÄ‚îÄblog/\n‚îÇ       ‚îÇ   index.qmd\n‚îÇ       ‚îî‚îÄ‚îÄ‚îÄposts/\n‚îÇ           ‚îî‚îÄ‚îÄ‚îÄ2023-09-24-first-post/     \n‚îÇ               ‚îÇ   index.ipynb\nYou‚Äôll notice that nbdev already added the _quarto.yml file. The main change we are making is adding a blog/ folder to the nbs/ directory. This directory has an index.qmd file that tells Quarto about our blog. Here‚Äôs an example index.qmd file that describes our blog and how its posts should be listed:\n---\ntitle: Example Blog\nsubtitle: Publishing with Quarto and nbdev\nlisting:\n  sort: \"date desc\"\n  contents: \"posts\"\n  sort-ui: false\n  filter-ui: false\n  categories: true\n  feed: true\npage-layout: full\n---\n\nEach post gets its own folder and a matching `index.ipynb` Notebook with the actual post's content. Eventually we can add photos, videos, and any other media that enhances the post.\n\nNext, we will leverage [Github Pages](https://pages.github.com/) to build and host our site for free. The screenshot below shows the settings we need on the Github site for our repo to be published as a blog. Concretely, we need to  `Deploy from a branch` and pick the `gh-pages` branch.\n\n![image.png](02_nbdev_files/figure-html/c0da2729-1-image.png)\n\nAnd that's all there is to it! We can now publish our first post. [Click here]() for a live link to this Notebook turned into a blog post. \n\nNow we've seen how `nbdev` lets us quickly create and setup a blog. Next we'll look at another one of its great capabilities: building a fully fledged python library.\n\n## Creating python libraries with `nbdev`\n\n`nbdev` has a set of helper commands that convert Notebooks into complete python libraries.  \n\nThese helper commands are called `directives` and usually go at the start of a code cell. They start with the special `#|` string which is similar to the shebang `#!` you may have seen in other scripts. These directive tell `nbdev` how to parse the code cell and what to do with it.\n\nFor example, the `default_exp` directive tells `nbdev` what to name an output python file. We use it below to name this specific python file as `lesson_2/simple_pipeline.py`: \n\n\nAfter we've named our soon-to-be python file, the `#| export` directive will parse and extract any python code cell we attach to it.\n\n::: {.cell 0='e' 1='x' 2='p' 3='o' 4='r' 5='t' execution_count=2}\n``` {.python .cell-code}\n# importing the pieces for the pipeline\nfrom transformers import AutoConfig\nfrom transformers import AutoTokenizer\nfrom transformers import AutoModelForSequenceClassification\n\n/Users/cck/mambaforge/envs/llm_base/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n  from .autonotebook import tqdm as notebook_tqdm\n\n:::\n\nA small annoyance: import statements have to be in their own code cell. We can‚Äôt pair them with function calls like print(), for example.\n\nNext, we refactor the code from the previous notebook (01_first_run.ipynb) into a simple class.\n::: {.cell 0=‚Äòe‚Äô 1=‚Äòx‚Äô 2=‚Äòp‚Äô 3=‚Äòo‚Äô 4=‚Äòr‚Äô 5=‚Äòt‚Äô execution_count=6}\nclass SentimentPipeline:\n    def __init__(self, model_name):\n        \"\"\"\n        Sentiment Analysis pipeline.\n        \"\"\"\n        self.model_name = model_name\n        self.config = AutoConfig.from_pretrained(self.model_name)\n        self.tokenizer = AutoTokenizer.from_pretrained(self.model_name)\n        self.model = AutoModelForSequenceClassification.from_pretrained(self.model_name)\n\n\n    def preprocess(self, text: str):\n        \"\"\"\n        Sends `text` through the LLM's tokenizer.  \n        The tokenizer turns words and characters into special inputs for the LLM.\n        \"\"\"\n        tokenized_inputs = self.tokenizer(text, return_tensors='pt')\n        return tokenized_inputs\n    \n\n    def forward(self, text: str):\n        \"\"\"\n        First we preprocess the `text` into tokens.\n        Then we send the `token_inputs` to the model.\n        \"\"\"\n        token_inputs = self.preprocess(text)\n        outputs = self.model(**token_inputs)\n        return outputs\n    \n\n    def process_outputs(self, outs):\n        \"\"\"\n        Here we mimic the post-processing that HuggingFace automatically does in its `pipeline`.  \n        \"\"\"\n        # grab the raw scores from the model for Positive and Negative labels\n        logits = outs.logits\n\n        # find the strongest label score, aka the model's decision\n        pred_idx = logits.argmax(1).item()\n\n        # use the `config` object to find the actual class label\n        pred_label = self.config.id2label[pred_idx]  \n\n        # calculate the human-readable probability score for this class\n        pred_score = logits.softmax(-1)[:, pred_idx].item()\n\n        # return the predicted label and its score\n        return {\n            'label': pred_label,\n            'score': pred_score, \n        }\n    \n\n    def __call__(self, text: str):\n        \"\"\"\n        Overriding the call method to easily and intuitively call the pipeline.\n        \"\"\"\n        model_outs = self.forward(text)\n        preds = self.process_outputs(model_outs)\n        return preds\n\n    \n    def __repr__(self):\n        \"\"\"\n        Cleaner representation of the pipeline.\n        \"\"\"\n        return f\"SentimentAnalysis_{self.model_name}\"\n:::\nLet‚Äôs now make sure that SentimentPipeline actually works, since live tests are one of the main benefits of Notebook coding! Note that since we don‚Äôt put an |# export directive in the cell below, it won‚Äôt be part of the exported python file either.\n\n# testing the pipeline\n\n# loading the default model\nmodel_name = 'distilbert-base-uncased-finetuned-sst-2-english'\nclassifier = SentimentPipeline(model_name) \n\n# make sure that the official HuggingFace example works as expected\nresults = classifier(\"We are very happy to show you the ü§ó Transformers library.\"); results\nassert results['label'] == 'POSITIVE'\n\nYou can think of the cell above as a unit test for the SentimentAnalysis pipeline. nbdev runs this notebook when it compiles the library, and if the tests fail then the build fails. This is a great, built-in way of making sure that the library works as expected.\n\n\nExporting the library\nWe can now export the library using the nbdev_build_lib command. This will create a file inside of the top-level library folder Fractal_LLM_Course. Per the default_exp directive, the file will called lesson_2/simple_pipeline.py.\n\nNote: we can add nested library directories with the typical python dot (.) syntax. For example, if we‚Äôd instead used the directive |# default_exp simple_pipeline, then the file would live at the top-level library folder: Fractal_LLM_Course/simple_pipeline.py. Adding the lesson_2. created the lesson_2/ folder for us.\n\nThe following set of commands will:\n- Export the Notebooks into a library.\n- Install the library as an editable install. - Import the newly installed library in a python shell.\nMake sure to run them from the top-level directory of the repo.\n# export Notebooks into a library\nnbdev_export_lib  \n\n# install the library as an editable install\npip install -e . \nNow open up a python shell to import and use the library.\n# import the newly installed library \nfrom Fractal_LLM_Course.lesson_2.simple_pipeline import SentimentPipeline\n\n# use our custom SentimentAnalysis pipeline!\nmodel_name = 'distilbert-base-uncased-finetuned-sst-2-english'\nclassifier = SentimentPipeline(model_name) \nCongrats! We‚Äôve now built and installed a full, working python library. This is just the start, nbdev has many other advanced tools you can read about here."
  },
  {
    "objectID": "03_cloud_gpus.html",
    "href": "03_cloud_gpus.html",
    "title": "Running LLMs in the Cloud",
    "section": "",
    "text": "Creating an LLM environment for Fine-Tuning in a cloud GPU.\nThere are many companies that offer GPUs in the Cloud. In this Notebook we choose Paperspace for its mix of ease and options.\nFirst, let‚Äôs go over some cloud providers that cover different use-cases and options:\n- Lambda Labs.\n- Paperspace.\n- Google Colab.\nLambda Labs is a very popular GPU cloud provider. It has great pricing. Unfortunately, its combo of popularity and low costs means that GPUs are often claimed and we‚Äôre not guaranteed to get one. Making an account and launching GPUs, when they are open, is incredibly fast and straightforward.\nPaperspace offers cloud GPUs in two different, complementary ways. Their platform called Gradient is built around Notebooks and is tailored for quick ML and scientific jobs. Their CORE service, on the other hand, has more low-level options. We use it to fully customize and deploy a VM with a GPU. Paperspace tends to have better availability than Lambda Labs.\nColab is an option provided by Google. It builds around their own flavor of Notebooks that is very similar to Jupyter‚Äôs. One of Colab‚Äôs most useful features is the ability to directly load a Notebook straight from any of your Git repos. It‚Äôs a convenient and flexible option without the overhead of Lambda or Paperspace."
  },
  {
    "objectID": "03_cloud_gpus.html#launching-a-gpu-vm-with-paperspace",
    "href": "03_cloud_gpus.html#launching-a-gpu-vm-with-paperspace",
    "title": "Running LLMs in the Cloud",
    "section": "Launching a GPU VM with Paperspace",
    "text": "Launching a GPU VM with Paperspace\nWe use Paperspace because it lets us deploy custom VMs in different ways.\nSign up for a Paperspace account or log in if you already have one. After logging in, you should land at a similar page to this one:\n\nThe Create a Machine button on the top-left takes us to the page for setting up and deploying VMs.\nOne of the first options is picking the OS on the VM. We use Ubuntu 22.04 to leverage its latest updates and improvements.\n\nNext we pick the OS that the VM will run. The screenshot below shows the Quadro M4000 GPU which is the cheapest option at $0.45 an hour.\n\nIt‚Äôs good to keep the cost of running these cloud VMs in mind, so we don‚Äôt get any billing surprises. Below we do some quick math to see the costs of running this GPU:\n\n# price of an hour for the Quadro M4000 GPU\nprice_per_hour = 0.45\n\n# leaving the machine on for a day\nday_cost = 24 * price_per_hour\n\n# leaving it on for a week\nweek_cost = 7 * day_cost\n\n# leaving it up for a month\nmonth_cost = 4 * week_cost\n\nprint(f\"\"\"\nQuadro M4000 Costs:\nHour:  ${price_per_hour:.2f}\nDay:   ${day_cost:.2f}\nWeek:  ${week_cost:.2f}\nMonth: ${month_cost:.2f}\n\"\"\")\n\n\nQuadro M4000 Costs:\nHour:  $0.45\nDay:   $10.80\nWeek:  $75.60\nMonth: $302.40\n\n\n\nLeaving it on for a full day isn‚Äôt too bad. But the cost rises quickly the longer we leave on the machine. This is even worse with the more expensive GPU cards. Thankfully, the fine-tuning we‚Äôll be doing should fit well within a day.\n\nVM‚Äôs connection to the outside world\nNext we get to pick how to connect to this VM from a local computer: \nIn this case we pick the ssh option.\nSome of you likely have keys already in ~/.ssh. If not, here are two good tutorial options for SSH setups. The first is this Lambda Labs SSH tutorial. The second is a video from Paperspace embedded below.\n::: {.cell 0=‚Äòh‚Äô 1=‚Äòi‚Äô 2=‚Äòd‚Äô 3=‚Äòe‚Äô execution_count=4}\n# embedding Paperspace's youtube ssh tutorial directly in a Notebook\nfrom IPython.display import YouTubeVideo\nYouTubeVideo('3E_C4H8XSGg', width=700, height=400)\n\n\n        \n        \n\n:::\nOnce you have your key, add it under the SSH Keys section of your Paperspace account before going forward:\n\nWe‚Äôre almost done setting up the VM. Back at the bottom of the creation page, Paperspace summarizes the VM configuration and its cost. If the summary looks good, go ahead and click the Create button to deploy the cloud VM.\n\nStart the machine by clicking Connect from the main page:\n\nOnce we connect to the machine, we need to install the nvidia drivers. This is the software that lets our Machine Learning algorithms take full advantage of the GPU.\nHere is an excellent and clear guide to install the nvidia drivers.\n\n\nAlternative to NVIDIA Driver Installation\nPaperspace also offers a VM ready-to-go for Machine Learning applications. It‚Äôs called ML-In-A-Box and includes the nvidia drivers. It‚Äôs a great option if you want to get up and running quickly, or just want to skip the driver installation step (understandable).\nThis pre-configured VM might not have the latest version of the drivers, but we can always fix that later.\nHere is a screenshot with both types of Machines: custom and ML-In-A-Box:"
  },
  {
    "objectID": "03_cloud_gpus.html#creating-the-llm_base-environment-in-the-vm",
    "href": "03_cloud_gpus.html#creating-the-llm_base-environment-in-the-vm",
    "title": "Running LLMs in the Cloud",
    "section": "Creating the llm_base environment in the VM",
    "text": "Creating the llm_base environment in the VM\nFor this example we‚Äôll use the ML-In-A-Box VM. But, the steps are roughly the same for the custom VM, after installing the nvidia drivers.\nThe steps below are mostly repeated from the first lesson on creating the Environment. The two main changes:\n- The requirements are pip-installed in a different order than on Mac.\n- We can now install the libraries in reqs_optim.txt to speed up the LLMs.\n## Setting up the Environment on a VM\n\n# connect to the Paperspace VM\nssh paperspace@some-ip-here\n\n# install mamba\ncurl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Miniforge3-$(uname)-$(uname -m).sh\"\nbash Miniforge3-$(uname)-$(uname -m).sh\n# NOTE: after installing mamba, refresh your terminal\n\n# clone the course repo\ngit clone https://github.com/enzokro/Fractal-LLM-Course.git\n\n# move in to the environment folder\ncd Fractal-LLM-Course/Fractal_LLM_Course/lesson_0/envs\n\n# create the base environment\nmamba env create -f environment.yml\n\n# activate the environment\nmamba activate llm_base\n\n# install the pytorch library\npython -m pip install -r reqs_torch.txt\n\n# install the python packages, after activating the env\npython -m pip install -r requirements.txt  \n\n# now, we can also install the extra packages to speed up LLMs\npython -m pip install -r reqs_optim.txt  \n\nChecking if we can use the GPU\nDrum roll‚Ä¶ moment of truth. Can we actually use the GPU with pytorch? Run the following python code in the terminal to find out:\n## first, make sure the `llm_base` environment is active\n## then, run the following python code in a shell\n\n# import the torch library\nimport torch\n\n# check if we can see the GPU\nprint(torch.cuda.is_available()) # should print \"True\"\nIf the above command shows True, we‚Äôre good to go! We now have the llm_base environment on a cloud VM with a working GPU.\n\n\nTying this approach to Fine-Tuning\nEventually, we‚Äôll reserve a stronger GPU (or more of the weaker ones) with more memory and resources to handle the LLM fine-tuning."
  },
  {
    "objectID": "03_cloud_gpus.html#summary",
    "href": "03_cloud_gpus.html#summary",
    "title": "Running LLMs in the Cloud",
    "section": "Summary",
    "text": "Summary\nThis notebook covered how to launch and connect to a cloud GPU running on Paperspace. We then created the llm_base environment on the VM, mimicking our local environment. That means any notebook or command we‚Äôve ran on our local computer can now run in the VM.\n\nAside(?): Going over CUDA driver install\n\nRecording the CUDA driver install process‚Ä¶\n\n\n\nAside(??): llm_base on Colab"
  },
  {
    "objectID": "00_setup.html",
    "href": "00_setup.html",
    "title": "Environment setups",
    "section": "",
    "text": "Running a Large Language Model using the HuggingFace Transformers API."
  },
  {
    "objectID": "00_setup.html#things-we-need-for-the-class",
    "href": "00_setup.html#things-we-need-for-the-class",
    "title": "Environment setups",
    "section": "Things we need for the class",
    "text": "Things we need for the class\nIn order to fully use a current, open source LLM, the first thing we need to do is set up a proper programming environment. The environment is a computing ecosystem with all the software libraries and packages needed to run an LLM.\nNote that setting up this environment is often one of the most time-consuming and challenging tasks when it comes to Machine Learning. There is no silver bullet or universal solution, as you will see by the dozens of tools that folks have come up with to tackle this problem (insert xkcd comic about competing standards).\nThe main point here is that setting up the environment is often annoying. It can even be straight up painful. It‚Äôs ok to feel lost or struggle with it. Please take some comfort in the fact that once we have the environment, many of the downstream tasks will feel easy by comparison!\nSo what makes building this environment so challenging? And why do we need it in the first place?\n\nSilent Failures in AI Models\nLLMs, and Machine Learning models more generally, often fail in different ways than other, standard software fails. For instance, classic bugs in regular software include: type mismatches, syntax errors, compilation errors, etc. In other words failures that clearly stem from a wrong operation (aka a bug) that snuck into the code. We wanted the computer to do X, but we told it by accident to do Y instead.\nIn contrast, ML models often have ‚Äúsilent‚Äù failures. There is no syntax or compilation error - the program still runs and completes fine. But, there is something wrong in the code: adding where we should have subtracted, grabbing the wrong element from a list, or using the wrong mathematical function. There is no type checker or compiler that would (or even could, for now) catch these errors.\nThe fix for the silent failures above is clear:\n- Carefully inspecting the code.\n- Monitoring and validating its outputs.\n- Clarity in both the algorithms and models we are using.\nThere is another, unfortunate kind of silent failure: version mismatches. Version failures happen when we use a different version of a programming library than the version originally used by the model. As the software libraries we rely on are frequently updated, both subtle and major changes in their internals can affect the output of a model. These failures are unfortunately immune to our careful logical checks.\nAvoiding these silent failures is the main reason for being consistent and disciplined with our model‚Äôs programming environment. A good environment setup keeps us focused on the important, conceptual part of our model instead of getting bogged down in managing software versions.\n\n\nLooking forward with our environment\nThere is a nice benefit to spending this much time and effort up front on our environment.\nWe will not only have a specialized environment to run and fine-tune a single LLM. We‚Äôll have a springboard and setup to keep up with the state of the art in the field. A setup to bring in groundbreaking improvements as they are released. And to weave in the latest and greatest models. The LLM world is our oyster, and the base environment the grain of sand soon-to-be pearls."
  },
  {
    "objectID": "00_setup.html#organizing-what-we-need",
    "href": "00_setup.html#organizing-what-we-need",
    "title": "Environment setups",
    "section": "Organizing what we need",
    "text": "Organizing what we need\nThe mamba package manager will handle the python version. Why Mamba? To start it is way fast and better than Anaconda, and it makes it easier to install OS and system-level packages we need outside of python.\nWe will use pip to install the actual python packages. Note that we could use mamba for this as well, but a few of the libraries need custom pip options to install.\n\nNote: Run pip install -e . to install a dynamic version of this package that tracks live code changes."
  },
  {
    "objectID": "00_setup.html#mac-installation",
    "href": "00_setup.html#mac-installation",
    "title": "Environment setups",
    "section": "Mac Installation",
    "text": "Mac Installation\nFirst find the name of your architecture. We then use it to pick the right install script for each Mac.\n\n# check your mac's architecture\narch=$(uname) \necho $arch\n\n# download the appropriate installation script\ncurl -L -O \"https://github.com/conda-forge/miniforge/releases/latest/download/Mambaforge-$(uname)-$(uname -m).sh\"\n\n# run the Mambaforge installer\nbash Mambaforge-$(uname)-$(uname -m).sh\nIf you prefer to download the file directly, grab it from here:\nhttps://github.com/conda-forge/miniforge/releases/"
  },
  {
    "objectID": "00_setup.html#creating-the-environment",
    "href": "00_setup.html#creating-the-environment",
    "title": "Environment setups",
    "section": "Creating the environment",
    "text": "Creating the environment\nAfter installing Mamba, head to the Lesson 0 here: Fractal_LLM_Course/lesson_0/envs. The README.md in that folder has the full instructions to build the mamba environment."
  }
]